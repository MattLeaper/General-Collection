{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dcaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "datafile = 'organamnist'\n",
    "\n",
    "# Download the dataset to the local folder\n",
    "if not os.path.isfile(f'./{datafile}.npz'):\n",
    "    urllib.request.urlretrieve(f'https://zenodo.org/records/10519652/files/{datafile}.npz?download=1', f'{datafile}.npz')\n",
    "\n",
    "# Load the compressed numpy array file\n",
    "dataset = np.load(f'./{datafile}.npz')\n",
    "\n",
    "# The loaded dataset contains each array internally\n",
    "for key in dataset.keys():\n",
    "    print(f'dict key: {key:12s}, array shape: {dataset[key].shape}, array datatpye: {dataset[key].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81888821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_ids, class_first_occur = np.unique(dataset['train_labels'], return_index=True)\n",
    "\n",
    "print(f'This dataset contains {len(class_ids)} classes.')\n",
    "\n",
    "\n",
    "Nrows = 3; Ncols = 4\n",
    "fig, ax = plt.subplots( Nrows, Ncols, sharex=True, sharey=True)\n",
    "\n",
    "for i in range(Nrows):\n",
    "    for j in range(Ncols):\n",
    "        if( i*Ncols + j < len(class_ids)):\n",
    "            idx = class_first_occur[i*Ncols + j]\n",
    "            label = dataset['train_labels'][idx,0]\n",
    "            ax[i,j].set_title(f'Class {label}')\n",
    "            ax[i,j].set_yticks([])\n",
    "            ax[i,j].set_xticks([])\n",
    "            ax[i,j].imshow(dataset['train_images'][idx], cmap='gray')\n",
    "        else:\n",
    "            ax[i,j].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4604eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(f'dict key: {key:12s}, array shape: {dataset[key].shape}, array dtype: {dataset[key].dtype}')\n",
    "\n",
    "X = dataset['train_images'].reshape(dataset['train_images'].shape[0], -1)  # Flatten the images\n",
    "y = dataset['train_labels'].flatten()\n",
    "\n",
    "kmeans = KMeans(n_clusters=11, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "cluster_labels = kmeans.predict(X)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "scatter1 = ax1.scatter(\n",
    "    X_pca[:, 0], X_pca[:, 1], X_pca[:, 2],\n",
    "    c=y, cmap='tab10', s=10\n",
    ")\n",
    "ax1.set_title(\"3D Plot with True Labels\")\n",
    "ax1.set_xlabel(\"PCA 1\")\n",
    "ax1.set_ylabel(\"PCA 2\")\n",
    "ax1.set_zlabel(\"PCA 3\")\n",
    "plt.colorbar(scatter1, ax=ax1)\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "scatter2 = ax2.scatter(\n",
    "    X_pca[:, 0], X_pca[:, 1], X_pca[:, 2],\n",
    "    c=cluster_labels, cmap='tab10', s=10\n",
    ")\n",
    "ax2.set_title(\"3D Plot with Cluster Labels\")\n",
    "ax2.set_xlabel(\"PCA 1\")\n",
    "ax2.set_ylabel(\"PCA 2\")\n",
    "ax2.set_zlabel(\"PCA 3\")\n",
    "plt.colorbar(scatter2, ax=ax2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1550cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################################################################\n",
    "#for the regression/knn methods\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['train_images'], dataset['train_labels'], random_state=0)  ## if not specified auto splits into 75%  train, 25% test\n",
    "\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "y_test_flat = y_test.reshape(y_test.shape[0], -1)\n",
    "y_train_flat = y_train.reshape(y_train.shape[0], -1)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "X_train_pca = pca.fit_transform(X_train_flat)\n",
    "X_test_pca = pca.transform(X_test_flat)\n",
    "\n",
    "############################################################################################################################################################################################################\n",
    "##### for the nn models\n",
    "\n",
    "X = dataset['train_images']  # Shape (N, H, W) where N is the number of samples\n",
    "y = dataset['train_labels']  # Shape (N, 1), single-label classes\n",
    "\n",
    "# Normalize images and convert to torch tensors\n",
    "X = X.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "X = torch.tensor(X)  # Convert to tensor\n",
    "\n",
    "# Flatten the labels to make them 1D\n",
    "y = y\n",
    "y = y.flatten()\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "  # Convert to tensor\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ebf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train_pca, y_train_flat)\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "\n",
    "KNN_Training_score = knn.score(X_train_pca, y_train_flat) * 100\n",
    "KNN_Accuracy_score = knn.score(X_test_pca, y_test_flat) * 100\n",
    "print(f\"train score\", KNN_Training_score)\n",
    "print(f\"test score\", KNN_Accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "log_reg_model.fit(X_train_pca, y_train_flat)\n",
    "\n",
    "y_pred_log_reg = log_reg_model.predict(X_test_pca)\n",
    "log_reg_train_score = log_reg_model.score(X_train_pca, y_train_flat) * 100\n",
    "log_reg_accuracy = accuracy_score(y_test_flat, y_pred_log_reg) * 100\n",
    "print(f\"Logistic Regression Train Accuracy: {log_reg_train_score:.4f}\")\n",
    "print(f\"Logistic Regression Test Accuracy: {log_reg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3eff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0978259",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    cnnepoch_acc = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {cnnepoch_acc:.2f}%')\n",
    "cnn_model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = cnn_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        val_total += labels.size(0)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "CNNtrain_score = cnnepoch_acc * 100\n",
    "print(f'Training Accuracy: {CNNtrain_score:.2f}%')\n",
    "val_accuracy = val_correct / val_total * 100\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f956007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "num_classes = 11\n",
    "num_epochs = 10\n",
    "fcnn_model = FCNN(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(fcnn_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fcnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = fcnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "fcnn_model.eval()\n",
    "fcnnval_correct = 0\n",
    "fcnnval_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = fcnn_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        fcnnval_total += labels.size(0)\n",
    "        fcnnval_correct += (predicted == labels).sum().item()\n",
    "FCNNTrain_score = epoch_acc * 100\n",
    "print(f\"Training Accuracy: {FCNNTrain_score:.2f}%\")\n",
    "fcnn_accuracy = fcnnval_correct / fcnnval_total * 100\n",
    "print(f\"Validation Accuracy: {fcnn_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82489797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracies for all models\n",
    "print(f\"Logistic Regression Test Accuracy: {log_reg_accuracy:.4f}%, Logisitic regression training score: {log_reg_train_score:.4f}%\")\n",
    "print(f\"FCNN Test Accuracy: {fcnn_accuracy:.4f}% FCNN train accuracy: {FCNNTrain_score:.4f}%\")\n",
    "print(f\"CNN Test Accuracy: {val_accuracy:.4f}%, CNN train accuracy: {CNNtrain_score:.4f}%\")\n",
    "print(f\"K nearest neighbors Test Accuracy: {KNN_Accuracy_score:.4f}%, KNN training score: {KNN_Training_score:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3cdce5",
   "metadata": {},
   "source": [
    "Logistic Regression Test Accuracy: 74.5168%, Logisitic regression training score: 75.5826%\n",
    "FCNN Test Accuracy: 92.0440% FCNN train accuracy: 91.3122%\n",
    "CNN Test Accuracy: 98.4956%, CNN train accuracy: 98.4411%\n",
    "K nearest neighbors Test Accuracy: 99.8264%, KNN training score: 100.0000%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "models = [fcnn_model, cnn_model, knn, log_reg_model]\n",
    "model_names = [\"FCNN\", \"CNN\", \"KNN\", \"Logistic Regression\"]\n",
    "labels = [str(i) for i in range(1, 12)]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if model == knn:\n",
    "        y_pred = model.predict(X_test_pca)\n",
    "        cm = confusion_matrix(y_test_flat, y_pred)\n",
    "    elif model == log_reg_model:\n",
    "        y_pred = model.predict(X_test_pca)\n",
    "        cm = confusion_matrix(y_test_flat, y_pred)\n",
    "    else:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        true_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                preds.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        true_labels = np.array(true_labels)\n",
    "\n",
    "        cm = confusion_matrix(true_labels, preds)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\", xticklabels=labels, yticklabels=labels, ax=axes[i])\n",
    "    axes[i].set_title(f\"Confusion Matrix - {model_names[i]}\")\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "    axes[i].set_ylabel(\"True\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com6018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
